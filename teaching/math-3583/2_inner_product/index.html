<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Inner product | Jiahui Chen</title> <meta name="author" content="Jiahui Chen"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/uark.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jiahuic.github.io/teaching/math-3583/2_inner_product/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jiahui </span>Chen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching and Mentoring</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/cv/">CV</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/talks/">Talks</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Inner product</h1> <p class="post-description"></p> </header> <article> <h3 id="21-dot-product-norm-distance-orthogonal-vectors"><strong>2.1 Dot Product, Norm, Distance, Orthogonal Vectors</strong></h3> <p>Let \(\mathbf{u},\mathbf{v} \in \mathbb R^n\) be given by \(\mathbf{u}=[u_1, \dots u_n]\) and \(\mathbf{v}=[v_1, \dots v_n]\), then their dot product is a scalar, mathematically denoted by \(\mathbf{u}\cdot \mathbf{v}\) and is given by</p> <p>\(\mathbf{u}\cdot \mathbf{v} = \text{dot}(\mathbf{u},\mathbf{v}) = u_1v_1 + u_2v_2 +\dots + u_nv_n \in \mathbb R\).</p> <h4 id="definition-1">Definition 1.</h4> <p>We say \(\mathbf{u}\) is <strong>orthogonal</strong> to \(\mathbf{v}\), if \(\mathbf{u}\cdot \mathbf{v} =0\).</p> <h4 id="definition-2">Definition 2.</h4> <p>Given a vector \(\mathbf{u}\), the <strong>norm</strong> (length) of \(\mathbf{u}\) is given by \(||\mathbf{u}|| = \sqrt{\mathbf{u}\cdot \mathbf{u}}\).</p> <h4 id="definition-3">Definition 3.</h4> <p>Given vectors \(\mathbf{u}, \mathbf{v} \in \mathbb R^n\), the <strong>distance</strong> between \(\mathbf{u}\) and \(\mathbf{v}\) is given by \(||\mathbf{u} - \mathbf{v}|| = \sqrt{(\mathbf{u}-\mathbf{v})\cdot (\mathbf{u}-\mathbf{v})}\).</p> <p>Use Python to compute the dot product between \(\mathbf{u} = [ 1, 7, 9, 11]\) and \(\mathbf{v} = [ 7, 1, 2, 2]\) (Store the information in a variable called <code class="language-plaintext highlighter-rouge">uv</code>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">]</span>
<span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">uv</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">uv</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>54
</code></pre></div></div> <p>Given two vectors \(\mathbf{u}\) and \(\mathbf{v}\) in \(\mathbb{R}^n\) (i.e. they have the same length), the “dot” product operation multiplies all of the corresponding elements and then adds them together. Ex:</p> <p>\(\mathbf{u} = [u_1, u_2, \dots, u_n]\) \(\mathbf{v} = [v_1, v_2, \dots, v_n]\)</p> \[\mathbf{u}\cdot \mathbf{v} = u_1 v_1 + u_2 v_2 + \dots + u_nv_n\] <p>or:</p> \[\mathbf{u}\cdot \mathbf{v} = \sum^n_{i=1} u_i v_i\] <p>This can easily be written as Python code as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">solution</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">u</span><span class="p">)):</span>
    <span class="n">solution</span> <span class="o">+=</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
<span class="n">solution</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>10
</code></pre></div></div> <h3 id="22-inner-products"><strong>2.2 Inner Products</strong></h3> <p><strong>Definition:</strong> An <strong>inner product</strong> on a vector space \(V\) (Remember that \(\mathbb{R}^n\) is just one class of vector spaces) is a function that associates a number, denoted as \(\langle \mathbf{u},\mathbf{v} \rangle\), with each pair of vectors \(\mathbf{u}\) and \(\mathbf{v}\) of \(V\). This function satisfies the following conditions for vectors \(\mathbf{u}, \mathbf{v}, \mathbf{w}\) and scalar \(c\):</p> <ul> <li>\(\langle \mathbf{u},\mathbf{v} \rangle = \langle \mathbf{v},\mathbf{u} \rangle\) (symmetry axiom)</li> <li>\(\langle \mathbf{u}+\mathbf{v},\mathbf{w} \rangle = \langle \mathbf{u},\mathbf{w} \rangle + \langle \mathbf{v},\mathbf{w} \rangle\) (additive axiom)</li> <li>\(\langle c\mathbf{u},\mathbf{v} \rangle = c\langle \mathbf{u},\mathbf{v} \rangle\) (homogeneity axiom)</li> <li>\(\langle \mathbf{u},\mathbf{u} \rangle \ge 0 \text{ and } \langle \mathbf{u},\mathbf{u} \rangle = 0 \text{ if and only if } \mathbf{u} = 0\) (positive definite axiom)</li> </ul> <p>The dot product of \(\mathbb{R}^n\) is an inner product. Note that we can define new inner products for \(\mathbb{R}^n\).</p> <p>Here is an example of a non-standard inner product in \(\mathbb{R}^n\):</p> <p>Consider two vectors \(\mathbf{x} = [x_1, x_2, \ldots, x_n]\) and \(\mathbf{y} = [y_1, y_2, \ldots, y_n]\). A new inner product, denoted \(\langle \mathbf{x}, \mathbf{y} \rangle'\), can be defined as:</p> \[\langle \mathbf{x}, \mathbf{y} \rangle' = \sum_{i=1}^{n} a_i x_i y_i\] <p>where \(a_i &gt; 0\) for all \(i\) (i.e., \(a_i\) are positive constants).</p> <p>This new inner product is still bilinear (additive + homogeneity), symmetric, and positive-definite, which makes it a valid inner product.</p> <p>For instance, let’s say \(a_i = i\) for all \(i\), the inner product of \(\mathbf{x}\) and \(\mathbf{y}\) becomes:</p> \[\langle \mathbf{x}, \mathbf{y} \rangle' = x_1 y_1 + 2 x_2 y_2 + 3 x_3 y_3 + \ldots + n x_n y_n\] <p>This is a perfectly valid inner product for vectors in \(\mathbb{R}^n\), and it’s clearly different from the standard dot product.</p> <p>Let \(\mathbb{R}^2\) have an inner (dot) product defined by: \(\langle (a_1,a_2),(b_1,b_2)\rangle = 2a_1b_1 + 3a_2b_2.\)</p> <h4 id="norm-of-a-vector">Norm of a vector</h4> <p><strong>Definition:</strong> Let \(V\) be an inner product space. The <strong>norm</strong> of a vector \(\mathbf{v}\) is denoted by \(\| \mathbf{v} \|\) and is defined by:</p> \[\| \mathbf{v} \| = \sqrt{\langle \mathbf{v}, \mathbf{v} \rangle}.\] <h4 id="angle-between-two-vectors">Angle between two vectors</h4> <p><strong>Definition:</strong> Let \(V\) be a real inner product space. The <strong>angle \(\theta\) between two nonzero vectors \(\mathbf{u}\) and \(\mathbf{v}\)</strong> in \(V\) is given by:</p> \[cos(\theta) = \frac{\langle \mathbf{u}, \mathbf{v} \rangle}{\| \mathbf{u} \| \| \mathbf{v} \|}.\] <h4 id="orthogonal-vectors">Orthogonal vectors</h4> <p><strong>Definition:</strong> Let \(V\) be an inner product space. Two vectors \(\mathbf{u}\) and \(\mathbf{v}\) in \(V\) are <strong>orthogonal</strong> if their inner product is zero:</p> \[\langle \mathbf{u}, \mathbf{v} \rangle = 0.\] <h4 id="distance">Distance</h4> <p><strong>Definition:</strong> Let \(V\) be an inner product space. The <strong>distance between two vectors (points) \(\mathbf{u}\) and \(\mathbf{v}\)</strong> in \(V\) is denoted by \(d(\mathbf{u},\mathbf{v})\) and is defined by:</p> \[d(\mathbf{u},\mathbf{v}) = \| \mathbf{u}-\mathbf{v} \| = \sqrt{\langle \mathbf{u}-\mathbf{v}, \mathbf{u}-\mathbf{v} \rangle}\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Define two complex vectors A and B
</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">2j</span><span class="p">,</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">3j</span><span class="p">,</span> <span class="mi">3</span> <span class="o">+</span> <span class="mf">4j</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">4</span> <span class="o">+</span> <span class="mf">5j</span><span class="p">,</span> <span class="mi">5</span> <span class="o">+</span> <span class="mf">6j</span><span class="p">,</span> <span class="mi">6</span> <span class="o">+</span> <span class="mf">7j</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The conjugate of B:</span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">conj</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>

<span class="c1"># Calculate the inner product
</span><span class="n">inner_product</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">conj</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The inner product is:</span><span class="sh">"</span><span class="p">,</span> <span class="n">inner_product</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The conjugate of B: [4.-5.j 5.-6.j 6.-7.j]
The inner product is: (88+9j)
</code></pre></div></div> <h3 id="221-inner-product-on-functions"><strong>2.2.1 Inner Product on Functions</strong></h3> <p>In functional analysis, an inner product on functions extends the concept of the dot product in finite-dimensional spaces to function spaces. Essentially, the inner product of two functions \(f\) and \(g\) is a complex number that provides a measure of the “similarity” between the two functions over a specified interval. The inner product of \(f\) and \(g\) in a Hilbert space (vector space) of square-integrable functions over an interval \([a, b]\) is commonly defined as:</p> <p>\(\)\langle f, g \rangle = \int_{a}^{b} f(x) \overline{g(x)} \, dx\(\)</p> <p>Here, \(\overline{g(x)}\) is the complex conjugate of \(g(x)\).</p> <p>This definition generalizes the dot product and retains many of its essential properties, including commutativity, linearity, and the identification of orthogonal functions. In this framework, functions themselves can be considered as vectors in an infinite-dimensional Hilbert space, and the operations of vector addition and scalar multiplication are defined pointwise.</p> <p>This concept is crucial for the study of various problems in mathematics, physics, and engineering, such as solving differential equations, quantum mechanics, and signal processing.</p> <h4 id="example">Example</h4> <p>Consider the following functions</p> <p>\(f(x)=3x-1\) \(g(x)=5x+3\)</p> <p>with inner product defined by \(\langle f,g\rangle=\int_0^1{f(x)\overline{g(x)}dx}.\)</p> <p>✅ <strong><font color="red">QUESTION:</font></strong> What is the norm of $f(x)$ in this space?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.integrate</span> <span class="kn">import</span> <span class="n">quad</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>

<span class="k">def</span> <span class="nf">inner_product</span><span class="p">(</span><span class="n">func1</span><span class="p">,</span> <span class="n">func2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="c1"># Compute the integral of func1(x) * conj(func2(x)) from a to b
</span>    <span class="n">result</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">conj</span><span class="p">(</span><span class="nf">func2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="nf">func1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

<span class="c1"># Compute the inner product of f and g over the interval [0, 1]
</span><span class="n">result</span> <span class="o">=</span> <span class="nf">inner_product</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">The inner product is </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The inner product is 0.25
</code></pre></div></div> <h3 id="23-polynomial-approximation"><strong>2.3 Polynomial Approximation</strong></h3> <p>Polynomial approximation is a critical topic in numerical analysis and applied mathematics. By approximating more complicated functions with simpler polynomial functions, we can solve or simplify many practical problems. In many scientific problems, it is desirable to approximate a complicated function by a simpler function. One common choice is to approximate the function of interest \(f(x)\) by a low-degree polynomial. The set of all polynomials of degree less than or equal to \(n\) forms a vector space \(P_n\). Specifically, \(P_n\) is the set of all functions of the form: \(f(x) = a_0 + a_1x + a_2x^2 + \cdots + a_dx^d,\) where \(a_0, a_1, \ldots, a_n\) are real numbers.</p> <h3 id="vector-space-properties">Vector Space Properties</h3> <p>A polynomial vector space retains all the fundamental properties of vector spaces:</p> <ol> <li> <strong>Closure under addition</strong>: The sum of two polynomials in \(P_n\) is also in \(P_n\).</li> <li> <strong>Closure under scalar multiplication</strong>: A polynomial in \(P_n\) scaled by a scalar is also in \(P_n\).</li> <li> <strong>Existence of Zero Vector</strong>: The zero polynomial \(f(x) = 0\) is in \(P_n\).</li> <li> <strong>Existence of Additive Inverses</strong>: For every polynomial \(f(x)\) in \(P_n\), there exists a polynomial \(-f(x)\) in \(P_n\) such that \(f(x) + (-f(x)) = 0\).</li> </ol> <h3 id="example-vector-addition">Example: Vector Addition</h3> <p>For \(f(x) = x + 1\) and \(g(x) = x^2 - 1\) in \(P_2\),</p> \[f(x) + g(x) = x^2 + x\] <p>The result is still a polynomial of degree less than or equal to 2, confirming closure under addition.</p> <h3 id="231-least-squares-polynomial-approximation"><strong>2.3.1 Least Squares Polynomial Approximation</strong></h3> <p>Another approach to find an approximating polynomial is the method of least squares, which minimizes the error between the polynomial and the function being approximated.</p> <h4 id="python-example">Python Example</h4> <p>Here’s a Python example using NumPy to generate a least squares polynomial approximation of degree 2 for the function \(f(x) = \sin(x)\) on the interval \([0, \pi]\). Change the variable <code class="language-plaintext highlighter-rouge">degree</code> to see how it converge to \(\sin(x)\).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Define the function and its domain
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Fit a polynomial of degree 2 (quadratic)
</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">coeff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>

<span class="c1"># Create the polynomial object
</span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">poly1d</span><span class="p">(</span><span class="n">coeff</span><span class="p">)</span> <span class="c1"># A one-dimensional polynomial class.
</span>
<span class="c1"># Evaluate the polynomial at the points x
</span><span class="n">y_fit</span> <span class="o">=</span> <span class="nf">p</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Plot the function and its approximation
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">sin(x)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_fit</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Approximation</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_13_0-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_13_0-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_13_0-1400.webp"></source> <img src="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_13_0.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="least_square" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="232-taylors-theorem"><strong>2.3.2 Taylor’s Theorem</strong></h3> <h4 id="introduction">Introduction</h4> <p>Taylor’s Theorem provides a way to approximate functions by polynomials. When we can’t solve a function explicitly, or when it’s computationally expensive to do so, Taylor series can offer a viable alternative by presenting a polynomial that approximates the function closely within a certain range.</p> <h4 id="theorem-of-single-variable">Theorem of Single Variable</h4> <p>If a function \(f\) is \(n\)-times differentiable on an interval \(I\) containing the point \(a\), and \(f^{(n+1)}(x)\) exists for each \(x\) in \(I\), then for each \(x\) in \(I\), there exists a number \(\eta\) between \(a\) and \(x\) such that: \(f(x) = f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 + ... + \frac{f^{(n)}(a)}{n!}(x-a)^n + \frac{f^{(n+1)}(\eta)}{(n+1)!}(x-a)^{n+1}\)</p> <p>The first \(n\) terms of this expansion constitute the \(n\)-th degree Taylor polynomial \(T_n(x) = f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \ldots + \frac{f^{(n)}(a)}{n!}(x-a)^n\) for \(f\) centered at \(a\). The last term is the remainder, \(R_n = \frac{f^{(n+1)}(\eta)}{(n+1)!}(x-a)^{n+1},\) which goes to zero faster than the largest power of \(x - a\) as \(x\) approaches \(a\) if \(f\) is \((n+1)\)-times differentiable at \(a\).</p> <p>A different, but equivalent, way to write is \(f(x+h) = f(x) + hf'(x) + \frac{h^2}{2!}f''(x) + \ldots + \frac{h^n}{n!}f^{(n)}(x) + R_n(x).\)</p> <h4 id="derivation">Derivation</h4> <p>To derive the Taylor series expansion for a function \(f(x)\) about the point \(x = a\):</p> <ol> <li> <p><strong>Zeroth Order Term:</strong> The value of the function at the point \(a\): \(f(a)\).</p> </li> <li> <p><strong>First Order Term:</strong> The first derivative gives the slope or rate of change of the function. By multiplying it with \((x - a)\), we determine the linear approximation of the function around the point \(a\).</p> </li> <li> <p><strong>Higher Order Terms:</strong> Similarly, the second derivative gives the rate of change of the rate of change, or curvature. We take into account this curvature by including a term proportional to \((x - a)^2\), and so forth for higher-order terms.</p> </li> </ol> <p>This continues for as many derivatives as we know or require, with each term capturing more intricate details of the function’s behavior near \(a\).</p> <h4 id="examples">Examples</h4> <p>The expansion of \(e^x\) about \(x = 0\): \(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + ...\)</p> <p>The expansion of \(\frac{1}{1-x}\) about \(x =0\): \(\frac{1}{1-x} = 1 + x + x^2 + x^3 + ...\)</p> <h4 id="theorem-of-two-variables">Theorem of Two Variables</h4> <p>The two-variable version of the expansion is \(f(x+h, t+k) = f(x,t) +Df(x,t) + \frac{1}{2}D^2f(x,t) + ... + \frac{1}{n!}D^nf(x,t) + R_n\) where \(D = h\frac{\partial}{\partial x} + k\frac{\partial}{\partial t}.\) Alternatively, writing this out yields \(f(x+h, t+k) = f(x,t) + hf_x(x,t) + kf_t(x,t) + \frac{1}{2}h^2f_{xx}(x,t) + hkf_{xt}(x, t) + \frac{1}{2}k^2f_{tt}(x,t) + ...\) The subscripts in the above expression denote partial differentiation, such as \(f_{xt}=\frac{\partial^2f}{\partial x\partial t}.\)</p> <h3 id="233-lagrange-interpolation"><strong>2.3.3 Lagrange Interpolation</strong></h3> <p>Lagrange Interpolation is another common method used for polynomial approximation. It’s designed to go through a specific set of points \((x_1, y_1), \ldots, (x_n, y_n)\) exactly.</p> <p>The Lagrange polynomial \(L(x)\) is given by:</p> \[L(x) = \sum_{i=1}^{n} y_i \cdot l_i(x)\] <p>where \(l_i(x)\) are the Lagrange basis polynomials:</p> <p>\(l_i(x) = \prod_{j \neq i} \frac{x - x_j}{x_i - x_j}\)</p> <h4 id="python-example-for-lagrange-interpolation">Python Example for Lagrange Interpolation</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.interpolate</span> <span class="kn">import</span> <span class="n">lagrange</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Sample points
</span><span class="n">x_points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">y_points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># Lagrange interpolation
</span><span class="n">poly</span> <span class="o">=</span> <span class="nf">lagrange</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">y_points</span><span class="p">)</span>

<span class="c1"># Evaluate polynomial
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">x_points</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">max</span><span class="p">(</span><span class="n">x_points</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">poly</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">y_points</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Lagrange Interpolation</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_17_0-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_17_0-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_17_0-1400.webp"></source> <img src="/assets/img/math-3583/2_Inner_product_files/2.Inner_product_17_0.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="lagrange_interpolation" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4 id="other-polynomial-approximations">Other Polynomial Approximations</h4> <ul> <li> <p><strong>Legendre Polynomial</strong>: Used in spectral methods to create an orthogonal basis with which you can expand your solution.</p> </li> <li> <p><strong>Hermite Polynomial</strong>: A class of orthogonal polynomials that arise in probability theory, quantum mechanics, and numerical analysis, among other fields.</p> </li> <li> <p><strong>Newton’s Interpolating Polynomial</strong>: Useful when adding new data points, as you don’t have to recompute the entire polynomial.</p> </li> <li> <p><strong>Chebyshev Approximation</strong>: Uses Chebyshev polynomials to minimize the maximum error in approximation. Effective in approximating functions over a specific interval.</p> </li> <li> <p><strong>Bernstein Polynomial</strong>: Used in the field of computer graphics, particularly in the design of curves and surfaces.</p> </li> <li> <p><strong>Spline Interpolation</strong>: Instead of using a single high-degree polynomial, splines use lower-degree polynomials for each interval between data points, ensuring smoother and more controlled behavior.</p> </li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Jiahui Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>